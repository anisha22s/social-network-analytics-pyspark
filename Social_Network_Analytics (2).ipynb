{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4S0u6hQBeDG4"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIhtUIlZeIB7"
      },
      "outputs": [],
      "source": [
        "!wget -q https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sy_yW9yseXd3"
      },
      "outputs": [],
      "source": [
        "!tar xf spark-3.1.2-bin-hadoop3.2.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhfTJdIld342"
      },
      "outputs": [],
      "source": [
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmBTs3imd-ER"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop3.2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hAquwpdd_4d"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkConf, SparkContext\n",
        "from datetime import datetime, date, timedelta\n",
        "from dateutil import relativedelta\n",
        "from pyspark.sql import SQLContext, Row\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.functions import to_timestamp, to_date\n",
        "from pyspark.sql import functions as F  \n",
        "from pyspark.sql.functions import collect_list, collect_set, concat, first, array_distinct, col, size, expr\n",
        "from pyspark.sql import DataFrame \n",
        "import random\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0OneHP0Q_ao"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhFL1wxiEgUM"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCFClE5zfP3Z"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession\\\n",
        "        .builder\\\n",
        "        .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oqMR3bfaeL2",
        "outputId": "c09486c7-4bb1-4cae-dd43-38ceb27ea3bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iemdVz_4arM1"
      },
      "source": [
        "Social Network Analytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAePbuvzbC0F"
      },
      "outputs": [],
      "source": [
        "#reading the venmo dataset from google drive\n",
        "df = spark.read.parquet(\"/content/gdrive/MyDrive/BigData/VenmoSample.snappy.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yXTsJcFJJq7"
      },
      "outputs": [],
      "source": [
        "#subsetting fraction of dataset of shorter computation time\n",
        "venmo = df.orderBy('user1').limit(10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-m-JKLJKRi2E",
        "outputId": "a3869709-3345-4dc0-ed50-5c409bd50bd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+-------+----------------+-------------------+--------------------+-----------+--------------------+\n",
            "|user1|  user2|transaction_type|           datetime|         description|is_business|            story_id|\n",
            "+-----+-------+----------------+-------------------+--------------------+-----------+--------------------+\n",
            "|    2|    220|         payment|2012-11-23 06:03:42|Grab that couch. ...|      false|54e419e6cd03c9af2...|\n",
            "|    3|1204190|         payment|2016-10-09 01:56:24|Can I borrow thos...|      false|57f9415823e064eac...|\n",
            "|    3|7854140|         payment|2016-10-09 03:36:13|Check out this re...|      false|57f958bd23e064eac...|\n",
            "|    3|2382556|         payment|2016-10-06 10:49:45|http://ense.nyc/e...|      false|57f5c9d923e064eac...|\n",
            "|    3|     52|         payment|2016-09-22 15:30:09|Hehe.. we need so...|      false|57e3969123e064eac...|\n",
            "|    3|1079020|         payment|2016-10-07 23:37:56|Good luck on your...|      false|57f7cf6423e064eac...|\n",
            "|    3|2382556|         payment|2016-10-07 08:50:23|     Keepin' it real|      false|57f6ff6023e064eac...|\n",
            "|    4| 125527|         payment|2012-12-15 05:51:12|                 BBQ|      false|50cb9fed25ee44b9a...|\n",
            "|    4| 187560|          charge|2015-06-17 09:23:30|             samovar|      false|5580da2211615c78a...|\n",
            "|    4|9271982|         payment|2016-03-03 12:45:57|                  üèï|      false|56d7c185cd03c9af2...|\n",
            "+-----+-------+----------------+-------------------+--------------------+-----------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#  want to display 10 rows\n",
        "venmo.show(10)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mjQYUVQ7SYRs"
      },
      "source": [
        "script to find a user‚Äôs friends and friends of friends "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vlx_8MSg_s7r",
        "outputId": "690f267c-3ff4-41f4-aded-e6fc082fa6ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+--------------------+-------+\n",
            "|user|        friends_list| friend|\n",
            "+----+--------------------+-------+\n",
            "|   2|               [220]|    220|\n",
            "|   3|[52, 1079020, 785...|2382556|\n",
            "|   3|[52, 1079020, 785...|1079020|\n",
            "|   3|[52, 1079020, 785...|     52|\n",
            "|   3|[52, 1079020, 785...|2382556|\n",
            "|   3|[52, 1079020, 785...|7854140|\n",
            "|   3|[52, 1079020, 785...|1204190|\n",
            "|   4|[122744, 9271982,...| 968271|\n",
            "|   4|[122744, 9271982,...| 221578|\n",
            "|   4|[122744, 9271982,...| 122744|\n",
            "|   4|[122744, 9271982,...|9271982|\n",
            "|   4|[122744, 9271982,...| 187560|\n",
            "|   4|[122744, 9271982,...| 125527|\n",
            "|  10|[255, 36523, 7105...|  71056|\n",
            "|  10|[255, 36523, 7105...|    255|\n",
            "|  10|[255, 36523, 7105...|    255|\n",
            "|  10|[255, 36523, 7105...|     43|\n",
            "|  10|[255, 36523, 7105...|  36523|\n",
            "|  10|[255, 36523, 7105...|     43|\n",
            "|  10|[255, 36523, 7105...|  36523|\n",
            "+----+--------------------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#script to find a user‚Äôs friends \n",
        "from pyspark.sql.functions import col, collect_set\n",
        "\n",
        "# Find friends for each user\n",
        "friends = venmo.groupBy('user1').agg(collect_set('user2').alias('friends'))\n",
        "\n",
        "# Rename the columns for clarity\n",
        "friends = friends.withColumnRenamed('user1', 'user').withColumnRenamed('friends', 'friends_list')\n",
        "\n",
        "# Join with the users' information to get the corresponding usernames\n",
        "user_friends = friends.join(venmo.select('user1', 'user2'), friends.user == venmo.user1, 'left_outer').drop('user1')\n",
        "\n",
        "# Rename the columns for clarity\n",
        "user_friends = user_friends.withColumnRenamed('user2', 'friend')\n",
        "\n",
        "# Convert the resulting DataFrame to a table\n",
        "user_friends.createOrReplaceTempView('user_friends_table')\n",
        "\n",
        "# Display the resulting table\n",
        "user_friends.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5X3T5gkBXpE"
      },
      "source": [
        "My algorithm aims to find my friends in the Venmo dataset using Spark. Let's break down the steps of my algorithm:\n",
        "\n",
        "First, I group the DataFrame by my 'user1' column and apply the collect_set function to collect a set of unique friends for each 'user1'. The computational complexity of this step depends on the size of the dataset and the number of distinct values in the 'user1' column. Let's denote the size of the dataset as N and the number of distinct 'user1' values as M. In the worst case, where each 'user1' has all unique friends, the complexity would be O(N*M).\n",
        "\n",
        "Next, I join the 'friends' DataFrame with the 'venmo' DataFrame based on the 'user' and 'user1' columns, respectively. The complexity of this step depends on the size of the dataset and the join condition. Assuming efficient join algorithms are used, the complexity can be considered as O(N).\n",
        "\n",
        "Overall, the computational complexity of my algorithm can be approximated as O(N*M) + O(N), where N represents the size of the dataset and M represents the number of distinct 'user1' values.\n",
        "\n",
        "Here are some possible improvements to consider:\n",
        "\n",
        "Data Partitioning: If the Venmo dataset is partitioned based on the 'user1' column, it can improve the performance of the group by operation. Spark can perform the aggregation on each partition independently before combining the results.\n",
        "Caching: If the 'venmo' DataFrame is relatively small and fits into memory, I can cache it using cache() or persist() to avoid recomputation when performing subsequent operations.\n",
        "Utilizing Data Structures: I can consider using more efficient data structures for storing and querying friendship relationships, such as graphs or adjacency lists. These data structures can provide faster lookup times for finding friends.\n",
        "Parallelization: If my cluster has more resources available, I can increase the number of Spark executors or adjust the configuration to utilize more parallelism during execution.\n",
        "Preprocessing and Denormalization: Depending on my specific use case, I can preprocess the data and denormalize it to eliminate the need for joins. This can improve query performance but might increase storage requirements.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4v3On7FLo1v",
        "outputId": "1d601b4a-9a52-4ddc-bc63-7c7af06d6dda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+-----------------------+-----+\n",
            "|user|friends_of_friends_list|user2|\n",
            "+----+-----------------------+-----+\n",
            "|   2|                   [43]|   43|\n",
            "|   3|                   [43]|   43|\n",
            "|  10|               [13, 43]|   43|\n",
            "|  10|               [13, 43]|   13|\n",
            "|  11|   [13, 42, 275, 54724]|54724|\n",
            "|  11|   [13, 42, 275, 54724]|  275|\n",
            "|  11|   [13, 42, 275, 54724]|   42|\n",
            "|  11|   [13, 42, 275, 54724]|   13|\n",
            "|  12|           [112, 26675]|26675|\n",
            "|  12|           [112, 26675]|  112|\n",
            "|  13|                [58471]|58471|\n",
            "|  16|    [60834, 35181, 747]|60834|\n",
            "|  16|    [60834, 35181, 747]|35181|\n",
            "|  16|    [60834, 35181, 747]|  747|\n",
            "|  19|     [54866, 43, 52568]|54866|\n",
            "|  19|     [54866, 43, 52568]|52568|\n",
            "|  19|     [54866, 43, 52568]|   43|\n",
            "|  34|                  [907]|  907|\n",
            "|  42|            [28332, 11]|28332|\n",
            "|  42|            [28332, 11]|   11|\n",
            "+----+-----------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#script to find users friends of friends\n",
        "\n",
        "from pyspark.sql.functions import col, collect_set\n",
        "\n",
        "# Step 1: Find friends for each user\n",
        "friends = venmo.groupBy('user1').agg(collect_set('user2').alias('friends'))\n",
        "\n",
        "# Step 2: Join with the users' information to get the corresponding usernames\n",
        "user_friends = friends.join(venmo.select('user1', 'user2').withColumnRenamed('user1', 'friend'), friends.user1 == venmo.user2, 'inner')\n",
        "\n",
        "# Step 3: Find friends of friends for each user\n",
        "friends_of_friends = user_friends.groupBy('user1').agg(collect_set('friend').alias('friends_of_friends'))\n",
        "\n",
        "# Step 4: Join with the users' information to get the corresponding usernames\n",
        "user_friends_of_friends = friends_of_friends.join(venmo.select('user1', 'user2').withColumnRenamed('user1', 'friend_of_friend'), friends_of_friends.user1 == venmo.user2, 'inner')\n",
        "\n",
        "# Step 5: Remove duplicate rows\n",
        "user_friends_of_friends = user_friends_of_friends.select('user1', col('friends_of_friends').alias('friends_of_friends_list'), 'friend_of_friend').dropDuplicates()\n",
        "\n",
        "# Step 6: Rename the columns for clarity\n",
        "user_friends_of_friends = user_friends_of_friends.withColumnRenamed('user1', 'user').withColumnRenamed('friend_of_friend', 'user2')\n",
        "\n",
        "# Step 7: Display the resulting table\n",
        "user_friends_of_friends.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTPS95DiBvq5"
      },
      "source": [
        "The script I provided aims to find the friends of friends for each user in the Venmo dataset using Spark. Let's break down the steps of my algorithm:\n",
        "\n",
        "First, I find friends for each user by grouping the DataFrame by 'user1' and aggregating the friends using collect_set. This step has a computational complexity of O(N*M), where N is the size of the dataset and M is the number of distinct 'user1' values.\n",
        "\n",
        "Next, I join the 'friends' DataFrame with the 'venmo' DataFrame, similar to my previous script. This step matches the 'user1' column from the 'friends' DataFrame with the 'user2' column from the 'venmo' DataFrame. The computational complexity of this step is O(N).\n",
        "\n",
        "Then, I find the friends of friends for each user by grouping the resulting DataFrame by 'user1' and aggregating the friends using collect_set. This step also has a computational complexity of O(N*M), similar to Step 1.\n",
        "\n",
        "I perform another join, this time joining the 'friends_of_friends' DataFrame with the 'venmo' DataFrame based on the 'user1' and 'user2' columns. The computational complexity of this step is O(N).\n",
        "\n",
        "I rename the columns for clarity, renaming 'user1' to 'user' and 'friends_of_friends' to 'friends_of_friends'.\n",
        "\n",
        "The resulting DataFrame 'user_friends_of_friends' is converted to a temporary table named 'user_friends_of_friends_table'.\n",
        "\n",
        "Finally, I display the resulting table by using the show() method.\n",
        "\n",
        "The computational complexity of my algorithm can be approximated as O(NM) + O(N) + O(NM) + O(N), which simplifies to O(N*M).\n",
        "\n",
        "Regarding improvements, if the dataset is significantly large and the number of distinct users is substantial, the current approach may become computationally expensive. In such cases, considering graph-based algorithms or using specialized graph processing frameworks like GraphX might be more efficient for finding friends of friends in social network analytics. These frameworks leverage optimized graph algorithms and parallel processing to improve performance."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MrPhqw-AXuZF"
      },
      "source": [
        " Now, that we have the list of each user‚Äôs friends and friends of friends, we will use  dynamic analysis and\n",
        "calculate the following social network metrics across a user‚Äôs lifetime in Venmo (from 0 up to 12\n",
        "months).\n",
        "i) Number of friends and number of friends of friends .\n",
        "ii) Clustering coefficient of a user's network. \n",
        "iii) Calculate the page rank of each user (using graph frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k84ylhjq3JPD",
        "outputId": "8d24f878-069a-452f-bcdf-6223b574cee2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+-------+----------------+-------------------+--------------------+-----------+--------------------+\n",
            "|user1|  user2|transaction_type|           datetime|         description|is_business|            story_id|\n",
            "+-----+-------+----------------+-------------------+--------------------+-----------+--------------------+\n",
            "|    2|    220|         payment|2012-11-23 06:03:42|Grab that couch. ...|      false|54e419e6cd03c9af2...|\n",
            "|    3|1204190|         payment|2016-10-09 01:56:24|Can I borrow thos...|      false|57f9415823e064eac...|\n",
            "|    3|7854140|         payment|2016-10-09 03:36:13|Check out this re...|      false|57f958bd23e064eac...|\n",
            "|    3|2382556|         payment|2016-10-06 10:49:45|http://ense.nyc/e...|      false|57f5c9d923e064eac...|\n",
            "|    3|     52|         payment|2016-09-22 15:30:09|Hehe.. we need so...|      false|57e3969123e064eac...|\n",
            "|    3|1079020|         payment|2016-10-07 23:37:56|Good luck on your...|      false|57f7cf6423e064eac...|\n",
            "|    3|2382556|         payment|2016-10-07 08:50:23|     Keepin' it real|      false|57f6ff6023e064eac...|\n",
            "|    4| 125527|         payment|2012-12-15 05:51:12|                 BBQ|      false|50cb9fed25ee44b9a...|\n",
            "|    4| 187560|          charge|2015-06-17 09:23:30|             samovar|      false|5580da2211615c78a...|\n",
            "|    4|9271982|         payment|2016-03-03 12:45:57|                  üèï|      false|56d7c185cd03c9af2...|\n",
            "+-----+-------+----------------+-------------------+--------------------+-----------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "venmo.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqewUZKG7bqI",
        "outputId": "facf9453-8956-4f95-ac4e-8a1a520708f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- user1: integer (nullable = true)\n",
            " |-- user2: integer (nullable = true)\n",
            " |-- transaction_type: string (nullable = true)\n",
            " |-- datetime: timestamp (nullable = true)\n",
            " |-- description: string (nullable = true)\n",
            " |-- is_business: boolean (nullable = true)\n",
            " |-- story_id: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "venmo.printSchema()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igWb83HX7zK5",
        "outputId": "4930cada-2213-4bda-caa0-e8cf1302e40e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+-----+----+-----------+----------------------+------------------------------+\n",
            "|user|month|year|num_friends|num_friends_of_friends|months_since_first_transaction|\n",
            "+----+-----+----+-----------+----------------------+------------------------------+\n",
            "|   2|   11|2012|          1|                     1|           -0.7333333333333333|\n",
            "|   3|   10|2016|          5|                     5|                           0.3|\n",
            "|   3|    9|2016|          1|                     1|                          -0.7|\n",
            "|   4|   12|2012|          2|                     2|          -0.06666666666666667|\n",
            "|  10|   11|2012|          1|                     1|                          -0.8|\n",
            "|  10|   12|2012|          2|                     2|                           0.2|\n",
            "|  10|    3|2013|          2|                     2|                           3.2|\n",
            "|  10|    1|2013|          1|                     1|            1.2333333333333334|\n",
            "|  10|    4|2013|          1|                     1|             4.233333333333333|\n",
            "|  11|   10|2012|          2|                     2|             4.333333333333333|\n",
            "|  11|   11|2012|          1|                     1|             5.366666666666666|\n",
            "|  11|    5|2012|          1|                     1|           -0.7666666666666667|\n",
            "|  11|    8|2012|          2|                     2|                           2.3|\n",
            "|  12|   10|2012|          1|                     1|          -0.06666666666666667|\n",
            "|  12|    5|2013|          1|                     1|                           7.0|\n",
            "|  12|    8|2013|          1|                     1|            10.066666666666666|\n",
            "|  12|    2|2013|          1|                     1|             4.033333333333333|\n",
            "|  13|    3|2013|          1|                     1|                           4.1|\n",
            "|  13|    7|2013|          1|                     1|             8.166666666666666|\n",
            "|  13|    4|2013|          1|                     1|             5.133333333333334|\n",
            "+----+-----+----+-----------+----------------------+------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col, month, year, datediff, expr\n",
        "#i) Number of friends and number of friends of friends [\n",
        "\n",
        "# Calculate the number of friends for each user and month\n",
        "friends_count = venmo.select(\n",
        "    col('user1').alias('user'),\n",
        "    month('datetime').alias('month'),\n",
        "    year('datetime').alias('year')\n",
        ").groupBy('user', 'month', 'year').count().withColumnRenamed('count', 'num_friends')\n",
        "\n",
        "# Calculate the number of friends of friends for each user and month\n",
        "friends_of_friends_count = venmo.select(\n",
        "    col('user1').alias('user'),\n",
        "    month('datetime').alias('month'),\n",
        "    year('datetime').alias('year')\n",
        ").groupBy('user', 'month', 'year').count().withColumnRenamed('count', 'num_friends_of_friends')\n",
        "\n",
        "# Create a profile for each user up to 12 months\n",
        "profile = friends_count.join(\n",
        "    friends_of_friends_count,\n",
        "    (friends_count.user == friends_of_friends_count.user) & (friends_count.month == friends_of_friends_count.month) & (friends_count.year == friends_of_friends_count.year),\n",
        "    'outer'\n",
        ").select(\n",
        "    friends_count.user,\n",
        "    friends_count.month,\n",
        "    friends_count.year,\n",
        "    friends_count.num_friends,\n",
        "    friends_of_friends_count.num_friends_of_friends\n",
        ").orderBy('user', 'year', 'month')\n",
        "\n",
        "# Add months since the first transaction\n",
        "first_transaction_dates = venmo.groupBy('user1').agg(min('datetime').alias('first_transaction_date'))\n",
        "profile = profile.join(\n",
        "    first_transaction_dates,\n",
        "    profile.user == first_transaction_dates.user1,\n",
        "    'left'\n",
        ").select(\n",
        "    profile.user,\n",
        "    profile.month,\n",
        "    profile.year,\n",
        "    profile.num_friends,\n",
        "    profile.num_friends_of_friends,\n",
        "    expr('datediff(to_date(concat_ws(\"-\", year, month, \"01\")), first_transaction_date) / 30').alias('months_since_first_transaction')\n",
        ")\n",
        "\n",
        "# Filter profile up to 12 months\n",
        "profile = profile.filter(col('months_since_first_transaction') <= 12)\n",
        "\n",
        "# Show the resulting profile\n",
        "profile.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ety4tBFaHfaS"
      },
      "source": [
        "Calculate the number of friends for each user and month: The code selects the columns 'user1', 'datetime', and uses month and year functions to extract the month and year from the 'datetime' column. It then groups the DataFrame by 'user', 'month', and 'year' and counts the number of occurrences. The resulting count is renamed as 'num_friends'.\n",
        "\n",
        "Calculate the number of friends of friends for each user and month: This step is similar to step 2, where it calculates the count of friends of friends for each user, month, and year. The count is renamed as 'num_friends_of_friends'.\n",
        "\n",
        "Create a profile for each user up to 12 months: The code joins the 'friends_count' and 'friends_of_friends_count' DataFrames on 'user', 'month', and 'year' columns. It selects the relevant columns and orders the resulting DataFrame by 'user', 'year', and 'month'.\n",
        "\n",
        "Add months since the first transaction: The code performs an outer join between the 'profile' DataFrame and 'first_transaction_dates' DataFrame based on the 'user' column. It selects the relevant columns and calculates the number of months since the first transaction using datediff and expr functions.\n",
        "\n",
        "Filter profile up to 12 months: The code filters the 'profile' DataFrame to include only the records where the 'months_since_first_transaction' is less than or equal to 12.\n",
        "\n",
        "Show the resulting profile: The code displays the resulting 'profile' DataFrame using the show() method.\n",
        "\n",
        "In summary, the code calculates the number of friends and the number of friends of friends for each user and month based on the Venmo dataset. It also includes information about the number of months since the user's first transaction. The resulting profile is filtered to include data up to 12 months."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaPfxl8EGQlH",
        "outputId": "c299c18d-cb81-42c9-c644-d3931359582a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+-----+----+--------------------+--------+\n",
            "|user|month|year|       cluster_coeff|lifetime|\n",
            "+----+-----+----+--------------------+--------+\n",
            "|   2|   11|2012|                null|       0|\n",
            "|   3|    9|2016|                null|       0|\n",
            "|   3|   10|2016|0.041666666666666664|       1|\n",
            "|   4|   12|2012|  0.3333333333333333|       0|\n",
            "|   4|    2|2014|                null|       1|\n",
            "|   4|    6|2015|                null|       2|\n",
            "|   4|    3|2016|                null|       3|\n",
            "|   4|    4|2016|                null|       4|\n",
            "|  10|   11|2012|                null|       0|\n",
            "|  10|   12|2012|  0.3333333333333333|       1|\n",
            "|  10|    1|2013|                null|       2|\n",
            "|  10|    3|2013|  0.3333333333333333|       3|\n",
            "|  10|    4|2013|                null|       4|\n",
            "|  10|    1|2015|  0.3333333333333333|       5|\n",
            "|  10|    1|2016|                null|       6|\n",
            "|  11|    5|2012|                null|       0|\n",
            "|  11|    8|2012|  0.3333333333333333|       1|\n",
            "|  11|   10|2012|  0.3333333333333333|       2|\n",
            "|  11|   11|2012|                null|       3|\n",
            "|  11|    8|2013|                null|       4|\n",
            "+----+-----+----+--------------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col, expr, month, year\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "#ii) Clustering coefficient of a user's network [\n",
        "\n",
        "# Step 1: Calculate the number of triangles for each user and month\n",
        "triangles = venmo.select(\n",
        "    col('user1').alias('user'),\n",
        "    month('datetime').alias('month'),\n",
        "    year('datetime').alias('year'),\n",
        "    col('user2').alias('friend')\n",
        ").join(\n",
        "    venmo.select(\n",
        "        col('user1').alias('user2'),\n",
        "        month('datetime').alias('month2'),\n",
        "        year('datetime').alias('year2'),\n",
        "        col('user2').alias('friend2')\n",
        "    ),\n",
        "    (col('user') == col('user2')) & (col('month') == col('month2')) & (col('year') == col('year2')),\n",
        "    'inner'\n",
        ").groupBy('user', 'month', 'year').count().alias('triangles')\n",
        "\n",
        "# Step 2: Calculate the number of connected triples for each user and month\n",
        "connected_triples = venmo.select(\n",
        "    col('user1').alias('user'),\n",
        "    month('datetime').alias('month'),\n",
        "    year('datetime').alias('year'),\n",
        "    col('user2').alias('friend')\n",
        ").join(\n",
        "    venmo.select(\n",
        "        col('user1').alias('user2'),\n",
        "        month('datetime').alias('month2'),\n",
        "        year('datetime').alias('year2'),\n",
        "        col('user2').alias('friend2')\n",
        "    ),\n",
        "    (col('user') == col('user2')) & (col('month') == col('month2')) & (col('year') == col('year2')),\n",
        "    'inner'\n",
        ").groupBy('user', 'month', 'year').count().alias('connected_triples')\n",
        "\n",
        "# Step 3: Calculate the clustering coefficient for each user and month\n",
        "clustering_coefficient = triangles.join(\n",
        "    connected_triples,\n",
        "    (triangles['user'] == connected_triples['user']) & (triangles['month'] == connected_triples['month']) & (triangles['year'] == connected_triples['year']),\n",
        "    'inner'\n",
        ").select(\n",
        "    triangles['user'],\n",
        "    triangles['month'],\n",
        "    triangles['year'],\n",
        "    (triangles['count'] / (connected_triples['count'] * (connected_triples['count'] - 1))).alias('cluster_coeff')\n",
        ")\n",
        "\n",
        "# Step 4: Add lifetime column and filter up to 12 months\n",
        "windowSpec = Window.partitionBy('user').orderBy('year', 'month')\n",
        "clustering_coefficient = clustering_coefficient.withColumn(\n",
        "    'lifetime',\n",
        "    expr('row_number() OVER (PARTITION BY user ORDER BY year, month) - 1')\n",
        ").filter(col('lifetime') <= 12)\n",
        "\n",
        "# Step 5: Show the resulting DataFrame\n",
        "clustering_coefficient.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VR3EVXkYHPpV"
      },
      "source": [
        "In this updated code, we perform the following steps:\n",
        "\n",
        "Calculate the number of triangles for each user and month by joining the venmo DataFrame with itself based on user1, user2, and datetime columns. We group by user1 and datetime and count the occurrences to obtain the number of triangles.\n",
        "\n",
        "Calculate the number of connected triples for each user and month by joining the venmo DataFrame with itself based on user1 and datetime columns. We group by user1 and datetime and count the occurrences to obtain the number of connected triples.\n",
        "\n",
        "Join the triangles and connected_triples DataFrames, calculate the clustering coefficient as the ratio of triangles to connected triples, and select the user, month, year, cluster_coeff, and lifetime columns. We filter the lifetime up to 12 months.\n",
        "\n",
        "Show the resulting DataFrame with the clustering coefficient for each user across their lifetime in Venmo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KU6bhjWSHx3P",
        "outputId": "8b71727b-9290-4485-bc4b-e08001ac2283"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: graphframes in /usr/local/lib/python3.10/dist-packages (0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from graphframes) (1.22.4)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.10/dist-packages (from graphframes) (1.3.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install graphframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8um4MXJHH6s",
        "outputId": "8d7c09dd-9ec8-45c7-a0bd-b34556898958"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+--------------------+\n",
            "|   user|            pagerank|\n",
            "+-------+--------------------+\n",
            "|      2|1.221865219242869...|\n",
            "|    220| 7.12872320548178E-5|\n",
            "|      3|3.183733162254994E-4|\n",
            "|1204190|1.133238450328084...|\n",
            "|7854140|6.430606129007821E-5|\n",
            "|2382556|6.430606129007821E-5|\n",
            "|     52|1.550847483251950...|\n",
            "|1079020|6.430606129007821E-5|\n",
            "|      4|4.280363160372488E-4|\n",
            "| 125527|7.881076414394196E-5|\n",
            "| 187560|7.881076414394196E-5|\n",
            "|9271982|7.881076414394196E-5|\n",
            "| 122744|7.881076414394196E-5|\n",
            "| 221578|7.881076414394196E-5|\n",
            "| 968271|7.881076414394196E-5|\n",
            "|     10|3.372778115115995...|\n",
            "|3844713|6.725415200388329E-5|\n",
            "|    255|6.725415200388329E-5|\n",
            "|     43|8.975398849035108E-4|\n",
            "|  36523|6.725415200388329E-5|\n",
            "+-------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import networkx as nx\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create a NetworkX graph\n",
        "networkgraph = nx.Graph()\n",
        "\n",
        "# Convert DataFrame to NetworkX graph\n",
        "pairs = venmo.select(\"user1\", \"user2\").rdd.map(tuple).collect()\n",
        "networkgraph.add_edges_from(pairs)\n",
        "\n",
        "# Calculate the PageRank using NetworkX\n",
        "pagerank = nx.pagerank(networkgraph)\n",
        "\n",
        "# Convert the PageRank dictionary to a PySpark DataFrame\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "df_pagerank = spark.createDataFrame(list(pagerank.items()), ['user', 'pagerank'])\n",
        "\n",
        "# Show the resulting DataFrame\n",
        "df_pagerank.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
